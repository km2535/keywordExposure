import json
import os
import csv
from datetime import datetime
from tabulate import tabulate
from src.config import OUTPUT_DIR, DATA_DIR

class Reporter:
    def __init__(self, results_path, category='cancer'):
        self.results_path = results_path
        self.category = category
        
    def load_results(self):
        """ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        if not os.path.exists(self.results_path):
            raise FileNotFoundError(f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.results_path}")
            
        with open(self.results_path, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    def generate_summary(self):
        """
        í‚¤ì›Œë“œ ë…¸ì¶œ ìš”ì•½ ìƒì„±
        - ë…¸ì¶œë˜ì§€ ì•Šì€ í‚¤ì›Œë“œì— ëŒ€í•´ ê°€ì¥ ìµœê·¼ì˜ ë…¸ì¶œ ì¼ì‹œ(latest_exposed_at)ì™€ í•´ë‹¹ URLì„ ê³„ì‚°í•˜ì—¬ ì¶”ê°€
        """
        results = self.load_results()
        now = datetime.now()
        
        summary = {
            "timestamp": results["timestamp"],
            "category": self.category,
            "exposed": [],
            "not_exposed": [],
            "partially_exposed": [], # ì¼ë¶€ ë…¸ì¶œ í‚¤ì›Œë“œë¥¼ ëª…í™•íˆ ë¶„ë¦¬
            "skipped_keywords": []   # URLì´ ì—†ì–´ ê±´ë„ˆë›´ í‚¤ì›Œë“œ (ë°œí–‰í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ)
        }
        
        for keyword_result in results["results"]:
            keyword = keyword_result["keyword"]
            urls = keyword_result["urls"]
            
            if not urls:
                # URLì´ ì—†ëŠ” í‚¤ì›Œë“œëŠ” 'ë°œí–‰í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ'ë¡œ ë¶„ë¥˜
                summary["skipped_keywords"].append({
                    "keyword": keyword,
                    "status": "URL ì—†ìŒ"
                })
                continue
            
            # ë…¸ì¶œ ìƒíƒœ í™•ì¸ ë° ê°œìˆ˜ ê³„ì‚°
            exposed_count = sum(1 for url in urls if url.get("is_exposed"))
            total_count = len(urls)
            is_fully_exposed = (exposed_count == total_count)
            is_any_exposed = (exposed_count > 0)

            
            if is_fully_exposed:
                summary["exposed"].append({
                    "keyword": keyword,
                    "status": f"ëª¨ë“  URL ë…¸ì¶œ ({exposed_count}/{total_count})"
                })
            elif is_any_exposed:
                # ì¼ë¶€ ë…¸ì¶œëœ í‚¤ì›Œë“œ
                summary["partially_exposed"].append({
                    "keyword": keyword,
                    "status": f"ì¼ë¶€ URL ë…¸ì¶œ ({exposed_count}/{total_count})"
                })
            else: # ëª¨ë“  URLì´ ë¯¸ë…¸ì¶œëœ ê²½ìš° (ğŸš¨ ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œ)
                
                # 1. ëª¨ë“  last_exposed_at ê°’ê³¼ URL ìŒ ìˆ˜ì§‘
                latest_exposed_data = [] # (datetime, url_raw)
                
                for url_entry in urls:
                    raw_date = url_entry.get('last_exposed_at')
                    if raw_date:
                        try:
                            dt = datetime.strptime(raw_date, "%Y-%m-%d %H:%M:%S")
                            latest_exposed_data.append((dt, url_entry.get('url', '')))
                        except ValueError:
                            pass

                # 2. ê°€ì¥ ìµœê·¼ì˜ ë…¸ì¶œ ì¼ì‹œ (Max) ì°¾ê¸° ë° í•´ë‹¹ URL ì¶”ì¶œ
                latest_exposed_at = None
                latest_exposed_url = None
                
                if latest_exposed_data:
                    # ê°€ì¥ ìµœê·¼ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
                    latest_exposed_data.sort(key=lambda x: x[0], reverse=True)
                    latest_exposed_at = latest_exposed_data[0][0]
                    latest_exposed_url = latest_exposed_data[0][1]
                
                # 3. ì¶œë ¥ ì •ë³´ ìƒì„±
                days_since_exposure = None
                last_exposed_info_str = "ê¸°ë¡ ì—†ìŒ"
                
                if latest_exposed_at:
                    # í˜„ì¬ ì‹œê°„ê³¼ì˜ ì°¨ì´ ê³„ì‚°
                    days_since_exposure = (now - latest_exposed_at).days
                    
                    last_exposed_info_str = f"{latest_exposed_at.strftime('%Y-%m-%d %H:%M:%S')} (D+{days_since_exposure})"
                
                
                summary["not_exposed"].append({
                    "keyword": keyword,
                    "status": f"ë…¸ì¶œ ì—†ìŒ (0/{total_count})",
                    "latest_exposed_at": latest_exposed_at,      # ì •ë ¬ ë° ì¶”ê°€ ì²˜ë¦¬ìš© datetime ê°ì²´
                    "latest_exposed_str": last_exposed_info_str, # HTML ì¶œë ¥ìš© ë¬¸ìì—´
                    "latest_exposed_url": latest_exposed_url     # CSVìš© ëŒ€í‘œ URL
                })
                
        return results, summary # ì›ë³¸ ê²°ê³¼ì™€ ìš”ì•½ ëª¨ë‘ ë°˜í™˜
        
    def export_csv_for_unexposed(self, all_results, summary):
        """
        ë…¸ì¶œë˜ì§€ ì•Šì€ í‚¤ì›Œë“œì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        í‚¤ì›Œë“œë‹¹ ê°€ì¥ ìµœê·¼ ë…¸ì¶œ ê¸°ë¡ì„ ê°€ì§„ URL í•˜ë‚˜ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.
        """
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        csv_filename = f'unexposed_keywords_summary_{self.category}.csv'
        csv_path = os.path.join(OUTPUT_DIR, csv_filename)
        
        # 'ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œ' ë¦¬ìŠ¤íŠ¸ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
        header = ["ì¹´í…Œê³ ë¦¬", "í‚¤ì›Œë“œ", "ëŒ€í‘œ URL", "ë§ˆì§€ë§‰ ë…¸ì¶œì¼ì‹œ"]
        data_rows = []
        
        # summary["not_exposed"]ì— ì´ë¯¸ í‚¤ì›Œë“œë³„ ëŒ€í‘œ ì •ë³´ê°€ ëª¨ë‘ ê³„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        for item in summary["not_exposed"]:
            
            # last_exposed_atì„ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ë˜, ê¸°ë¡ì´ ì—†ìœ¼ë©´ "ê¸°ë¡ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
            last_exposed_str = item["latest_exposed_at"].strftime("%Y-%m-%d %H:%M:%S") if item["latest_exposed_at"] else "ê¸°ë¡ ì—†ìŒ"
            
            row = [
                self.category,
                item["keyword"],
                item["latest_exposed_url"] if item["latest_exposed_url"] else "N/A", # ëŒ€í‘œ URL
                last_exposed_str
            ]
            
            data_rows.append(row)

        with open(csv_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(header)
            writer.writerows(data_rows)
            
        print(f"ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œ ìš”ì•½ CSVê°€ {csv_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return csv_path, csv_filename

    def print_report(self):
        """ì½˜ì†”ì— ë³´ê³ ì„œ ì¶œë ¥"""
        _, summary = self.generate_summary() # summaryë§Œ ì‚¬ìš©
        
        print("\n" + "=" * 50)
        print(f" ë„¤ì´ë²„ ê²€ìƒ‰ ë…¸ì¶œ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ - {self.category.upper()}")
        print("=" * 50)
        print(f"ìƒì„± ì‹œê°„: {summary['timestamp']}")
        
        # 1. ë…¸ì¶œëœ í‚¤ì›Œë“œ (ì „ì²´ + ì¼ë¶€)
        all_exposed = summary["exposed"] + summary["partially_exposed"]
        print("\n[âœ… ë…¸ì¶œëœ í‚¤ì›Œë“œ (ì „ì²´ ë° ì¼ë¶€)]")
        if all_exposed:
            exposed_data = [(item["keyword"], item["status"]) for item in all_exposed]
            print(tabulate(exposed_data, headers=["í‚¤ì›Œë“œ", "ìƒíƒœ"], tablefmt="grid"))
        else:
            print("ë…¸ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        # 2. ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œ (ì¡°ì¹˜ í•„ìš”)
        print("\n[ğŸš¨ ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œ (ì¡°ì¹˜ í•„ìš”)]")
        if summary["not_exposed"]:
            # HTMLìš© ë¬¸ìì—´ í•„ë“œ ì‚¬ìš©
            not_exposed_data = [
                (item["keyword"], item["status"], item["latest_exposed_str"]) 
                for item in summary["not_exposed"]
            ]
            print(tabulate(not_exposed_data, headers=["í‚¤ì›Œë“œ", "ìƒíƒœ", "ë§ˆì§€ë§‰ ë…¸ì¶œì¼ì‹œ"], tablefmt="grid"))
        else:
            print("ë…¸ì¶œ ì´íƒˆ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        # 3. ë°œí–‰í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ (URL ì—†ìŒ)
        print("\n[ğŸ“ ë°œí–‰í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ (URL ì„¤ì • ì—†ìŒ)]")
        if summary["skipped_keywords"]:
            skipped_data = [(item["keyword"], item["status"]) for item in summary["skipped_keywords"]]
            print(tabulate(skipped_data, headers=["í‚¤ì›Œë“œ", "ìƒíƒœ"], tablefmt="grid"))
        else:
            print("ë°œí–‰í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    def export_json(self):
        """JSON í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²°ê³¼ ë‚´ë³´ë‚´ê¸° - ì •í™•í•œ í˜•ì‹ ìœ ì§€"""
        results, _ = self.generate_summary() # ì›ë³¸ ê²°ê³¼ë§Œ ì‚¬ìš©
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        json_path = os.path.join(OUTPUT_DIR, f'latest_results_{self.category}.json')
        
        # ì›ë³¸ JSON êµ¬ì¡° ìœ ì§€
        export_data = {
            "timestamp": results["timestamp"],
            "results": results["results"]
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ë®ì–´ì“°ê¸°)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=4)
            
        print(f"JSON ê²°ê³¼ê°€ {json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return json_path